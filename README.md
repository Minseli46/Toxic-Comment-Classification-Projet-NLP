# üìö Projet : Classification de Commentaires Toxiques

## üéØ Objectif du projet
L‚Äôobjectif de ce projet est de d√©tecter automatiquement les commentaires toxiques post√©s sur une plateforme en ligne.  
Chaque commentaire doit √™tre classifi√© dans une ou plusieurs cat√©gories de toxicit√© :  
- **TOXIC** : propos g√©n√©raux toxiques  
- **OBSCENE** : propos vulgaires ou obsc√®nes  
- **INSULT** : insultes directes  
- **IDENTITY_HATE** : discours haineux ciblant une identit√© (race, religion, genre, ‚Ä¶)  

**Pourquoi ?**  
- Prot√©ger la plateforme et ses utilisateurs des discours haineux ou inappropri√©s  
- Automatiser la mod√©ration pour minimiser la responsabilit√© l√©gale  

---


### Consignes de travail

1. **Jeu de donn√©es**  
   - Utilisez le dataset fourni pour l‚Äôentra√Ænement.  
   - Au d√©marrage, travaillez sur un sous-ensemble pour acc√©l√©rer les it√©rations.

2. **Approche it√©rative**  
   - **√âtape 1** : Mod√®le de base (TF‚ÄìIDF + Logistic Regression ou SVM) pour √©valuer la difficult√© du probl√®me.  
   - **√âtape 2** : Passage √† un mod√®le de deep learning (embeddings, RNN/LSTM ou GRU).  
   - **√âtape 3** : Affinage du pipeline (pr√©traitements, r√©glage d‚Äôhyperparam√®tres).

3. **Pipeline de classification**  
   - **Pr√©traitement** : nettoyage, tokenisation, suppression des stop-words, lemmatisation.  
   - **Repr√©sentation** : TF‚ÄìIDF / Word2Vec / GloVe / embeddings contextuels (BERT, etc.).  
   - **Mod√©lisation** : classifieur lin√©aire puis RNN.  
   - **√âvaluation** : matrice de confusion, F1-score, ROC AUC.

---

## üõ†Ô∏è Approche utilis√©e

1. **Exploration et pr√©traitement des donn√©es**  
   - Chargement du dataset de commentaires  
   - Analyse de la distribution des classes  
   - Nettoyage :  
     - Passage en minuscules  
     - Suppression des caract√®res sp√©ciaux  
     - Tokenization et padding des s√©quences  

2. **Mod√®le de base : TF‚ÄìIDF + Na√Øve Bayes**  
   - Transformation TF‚ÄìIDF des textes  
   - Entra√Ænement d‚Äôun classifieur Multinomial Na√Øve Bayes  
   - **Bilan :** rapide √† entra√Æner, mais mauvaise d√©tection des classes rares (ex. IDENTITY_HATE)  

3. **Mod√®le avanc√© : Word Embeddings + LSTM**  
   - Embeddings de mots (Word2Vec-like)  
   - R√©seau de neurones r√©current (LSTM) pour capter les d√©pendances s√©quentielles  
   - Activation Sigmoid pour la classification multi-label  

4. **Optimisations apport√©es**  
   - Sur-√©chantillonnage de la classe **IDENTITY_HATE**  
   - Ajustement du seuil de d√©cision (passage de 0.5 √† 0.4)  
   - Early Stopping pour √©viter l‚Äôoverfitting  
   - Dropout pour r√©gularisation  

---


### Rendu 

1. **Rapport (max. 5 pages) disponible dans le d√©pot**  
   - **Contexte & sujet** : enjeux de la mod√©ration automatique.  
   - **Description des donn√©es** et de l‚Äôapproche.  
   - **D√©tails de la solution** : choix de mod√®le, architecture, pipeline.  
   - **R√©sultats & m√©triques** : comparatif entre versions it√©ratives.  
   - **Perspectives d‚Äôam√©lioration** : suggestions pour aller plus loin.  


---

### Technologies & biblioth√®ques

- **Langage :** Python 3.x  
- **Notebook :** Jupyter  
- **Pr√©traitement :** NLTK / spaCy  
- **ML classique :** scikit-learn  
- **Deep learning :** TensorFlow / PyTorch, Keras  
- **Embeddings :** Gensim, Transformers (Hugging Face)  
- **Visualisation :** Matplotlib, Seaborn  

---


## ‚úÖ R√©sum√© final

Ce projet d√©montre la mise en place d‚Äôun pipeline complet :  
- Pr√©traitement et analyse exploratoire  
- Mod√®le de base puis deep learning  
- Optimisations cibl√©es pour am√©liorer la d√©tection des classes rares  
- Bilan chiffr√© et perspectives d‚Äôam√©lioration  
